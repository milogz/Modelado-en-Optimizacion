{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c42bd1cc-d2d1-4997-8e88-2b6a13d35470",
   "metadata": {},
   "source": [
    "# Modelado en Optimización (IIND-2501)\n",
    "## Módulo 3 - Tipos de problemas de optimización y principales estrategias de solución"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41819d17-47e9-46d8-a2c3-d62eabe84734",
   "metadata": {},
   "source": [
    "El foco de la primera parte del curso estuvo en cómo **modelar problemas de decisión** y resolverlos a través de la optimización, acudiendo a herramientas como PuLP (Python) o Excel-Solver. Este módulo se enfoca en **conocer el proceso de solución** de un problema de optimización, introduciendo las estrategias de solución comunes para diferentes tipos de problemas (lineales, no lineales, continuos, enteros) y en diferentes contextos. Específicamente, conoceremos:\n",
    "- *qué hacen internamente los solvers* cuando resolvemos problemas de optimización de diferentes tipos, y\n",
    "- *cómo las herramientas de estadística y machine learning usan la optimización* para ajustar \"modelos que aprenden\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2400c63-ea68-4daf-8fbe-05f250d6d8c5",
   "metadata": {},
   "source": [
    "### Recapitulación de los *Módulos de Modelamiento* (semanas 1 a 8)\n",
    "\n",
    "En la primera mitad del curso, nos familiarizamos con la formulación de modelos de optimización de la forma:\n",
    "\n",
    "$$\\max\\ z = 3x_1 + 2x_2$$\n",
    "\n",
    "Sujeto a:\n",
    "$$\n",
    "\\begin{aligned}\n",
    "x_1 + x_2 &\\le 6 \\\\\n",
    "x_1 + 2 x_2 &\\le 8 \\\\\n",
    "2 x_2 + x_2 &\\le 8 \\\\\n",
    "x_1, x_2 &\\ge 0 \\, .\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "Con esta forma de modelamiento (*programación lineal*), formulamos problemas de distribución de productos, manejo de inventarios, o planeación de actividades, entre otros. De álgebra lineal sabemos que estos modelos se pueden representar de forma matricial. Por ejemplo, si definimos:\n",
    "\n",
    "$$\n",
    "A =\n",
    "\\begin{bmatrix}\n",
    "1 & 1 \\\\\n",
    "1 & 2 \\\\\n",
    "2 & 1\n",
    "\\end{bmatrix},\n",
    "\\quad\n",
    "b =\n",
    "\\begin{bmatrix}\n",
    "6 \\\\ 8 \\\\ 8\n",
    "\\end{bmatrix},\n",
    "\\quad\n",
    "c =\n",
    "\\begin{bmatrix}\n",
    "3 \\\\ 2\n",
    "\\end{bmatrix}.\n",
    "$$\n",
    "\n",
    "Podemos reescribir el problema original equivalentemente como:\n",
    "\n",
    "$$\\max\\; c^{T} x$$\n",
    "$$\\text{s.a.}$$\n",
    "$$A x \\le b,\\;$$\n",
    "$$x\\ge 0,\\;$$\n",
    "$$x\\in\\mathbb{R}^2.$$\n",
    "\n",
    "Así, podemos pensar en $x$ como el vector que representa las variables de decisión de un problema de optimización, en $c^{T}x$ como una función objetivo lineal, y en $A x \\le b$ como un conjunto de restricciones lineales.\n",
    "\n",
    "Si lo pensamos de forma general para un problema de optimización con $n$ variables y $m$ restricciones, $A\\in\\mathbb{R}^{m\\times n}$ contiene los coeficientes de las variables en las restricciones, $b\\in\\mathbb{R}^{m}$ contiene los términos independientes (lado derecho) de las restricciones, y $c\\in\\mathbb{R}^{n}$ contiene los costos asociados a las variables en la función objetivo (*ver diapositivas*)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9d9b090-7ae3-4f26-9833-d041a78c009d",
   "metadata": {},
   "source": [
    "### Temática para el Módulo de Métodos de Solución (semanas 9 a 12)\n",
    "\n",
    "En este módulo pasaremos de formular problemas reales como modelos matemáticos a encontrar la mejor decisión (o solución) para dichos modelos.\n",
    "\n",
    "Además de problemas lineales como el de la sección anterior, existen otros tipos de problemas de optimización con aplicaciones muy relevantes en la práctica actualmente. La siguiente tabla resume los tipos de problemas de optimización más comunes, junto a algunos casos de aplicación y métodos de solución típicos en cada tipo de problema."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "235aafc0-5725-4c2e-8d33-9e81a8a5028f",
   "metadata": {},
   "source": [
    "| | **No lineal sin restricciones** | **Lineal con restricciones (LP)** | **No lineal con restricciones (NLP)** | **Entero lineal (ILP/MILP)** |\n",
    "|:--|:--:|:--:|:--:|:--:|\n",
    "| **Forma general** | $$\\min\\; f_{nonlinear}(x) $$ $$x\\in\\mathbb{R}^n$$ | $$\\min\\; f(x)=c^{T}x $$ $$A x \\le b,\\;$$ $$x\\in\\mathbb{R}^n$$ | $$\\min\\; f_{nonlinear}(x)$$ $$g(x) \\le b,\\;$$ $$x\\in\\mathbb{R}^n$$ | $$\\min\\; f(x)=c^{T}x $$ $$A x \\le b,\\;$$ $$x\\in\\mathbb{Z}^n$$ |\n",
    "| **Ejemplos de aplicación** | Ajuste de parámetros sin restricciones (estadística, *machine learning*, métodos numéricos) | Mezclas, asignación, planeación de producción, manejo de inventarios | Diseño de ingeniería con procesos físicos, portafolios con riesgo no lineal | *Scheduling*, ruteo, selección de proyectos |\n",
    "| **Métodos típicos de solución** | Gradiente y sus variantes, heurísticas y aproximaciones numéricas | Simplex, Punto Interior | Programación cuadrática o convexa (via *solvers*), métodos numéricos | Branch & Bound (via *solvers*), heurísticas, metaheurísticas |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acf5cfd6-be10-405a-b0d3-f096fe4be608",
   "metadata": {},
   "source": [
    "Durante este módulo, exploraremos qué utilidad tienen estos tipos de problemas, qué particularidades presentan a la hora de encontrar la mejor solución ($x^{\\ast}$), y qué estrategias se utilizan para resolverlos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fb73324-05af-4d33-9ee2-00353bcb74aa",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Concepto básico de búsqueda iterativa \n",
    "\n",
    "Partiendo de un problema de optimización dado, queremos encontrar los valores óptimos del **vector de variables de decisión** $\\mathbf{x}$. El *proceso* de optimización consiste en encontrar los valores de $\\mathbf{x}$ que cumplen con las restricciones establecidas y ofrecen la mejor función objetivo posible. \n",
    "\n",
    "Dependiendo del tipo de problema, existen métodos basados en derivadas, en álgebra lineal, o en procedimientos algorítmicos, que definen reglas para avanzar en la búsqueda de la mejor solución. Independientemente del método, la optimización se basa en un proceso iterativo de búsqueda que parte de una solución inicial $\\mathbf{x}^{(t=0)}$ y actualiza los valores del vector $\\mathbf{x}$ a lo largo de iteraciones ($t=1,2,...,T_{max}$) hasta encontrar la mejor solución o agotar un máximo de iteraciones. \n",
    "\n",
    "En cada iteración, se hace un movimiento partiendo del vector de decisión actual $\\mathbf{x}^{(t)}$, y \"avanzando\" una longitud $\\alpha^{(t)}$ en la dirección $\\mathbf{\\Delta x}^{(t)}$, las cuales conducen a un nuevo vector de decisiones $\\mathbf{x}^{(t+1)}$.\n",
    "\n",
    "$$\\mathbf{x}^{(t+1)} = \\mathbf{x}^{(t)} + \\alpha^{(t)} \\mathbf{\\Delta x}^{(t)}$$\n",
    "\n",
    "La forma de avanzar de un $\\mathbf{x}^{(t)}$ al siguiente (i.e., la dirección y longitud de movimiento) depende del tipo de método, que a su vez depende del tipo de problema. En algunos casos, estos movimientos están basados en ecuaciones vectoriales mientras que en otros se hacen mediante reglas algorítmicas generales o acordes al problema. En este módulo, conoceremos estrategias de búsqueda de la mejor solución para problemas de optimización en diferentes contextos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f18c37e5-7a41-424a-b485-93f2c5ba6f6a",
   "metadata": {},
   "source": [
    "### Estructura del módulo\n",
    "\n",
    "Durante este módulo, conoceremos estrategias de solución para problemas de optimización comunes en la práctica: desde encontrar el mínimo de una función, hasta resolver problemas de decisión continuos y discretos, en casos lineales y no lineales. Específicamente, nos concentraremos en los siguientes tres bloques.\n",
    "\n",
    "1. **Optimización sin restricciones** (Semana 9): Contrastaremos procedimientos basados en vecindarios (búsqueda local) y basados en derivadas (búsqueda de gradiente) para optimizar funciones no lineales sin restricciones, introduciendo nociones de *óptimo local/global*, *incumbente*, y *convergencia* (**Lección 3.1**). Estudiaremos el uso del *descenso de gradiente* para la optimización en problemas de regresión, introduciendo la noción de *función de pérdida* como base para los problemas de estimación en *machine learning* e inteligencia artificial (**Lección 3.2**).\n",
    "   \n",
    "2. **Optimización lineal con restricciones** (Semanas 10 y 11): Retomaremos problemas de decisión como los cubiertos en la primera parte del curso, e introduciremos conceptos de *programación lineal* (y método Simplex) como estrategia vigente y base para análisis económico y métodos avanzados (**Lecciones 3.3, 3.4, y 3.5**). Como complemento (opcional), tendremos una lección introductoria que extiende las nociones al caso de la optimización no lineal (**Lección 3.6**), presentando problemas comunes y herramientas de solución disponibles.\n",
    "   \n",
    "3. **Optimización en problemas de decisiones discretas** (Semana 12): Exploraremos los retos asociados a la solución de problemas con variables enteras o binarias, presentando estrategias aproximadas (heurísticas) como alternativa práctica de solución para problemas difíciles de resolver con métodos exactos. (**Lecciones 3.7 y 3.8**)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd4a8949-1b4a-4424-98b8-0668a8455397",
   "metadata": {},
   "source": [
    "### Objetivos de aprendizaje\n",
    "\n",
    "Como complemento al contenido previo sobre modelamiento, este módulo ofrece una introducción a los procedimientos de solución de problemas de optimización, como elemento clave bajo lineamientos ABET e INFORMS. Al finalizar, el estudiante estará en capacidad de:\n",
    "\n",
    "- Describir el **esquema general de procedimientos de búsqueda en optimización**, incluyendo búsqueda local y métodos basados en gradientes, aplicados a funciones de costo o pérdida en contextos operacionales y de analítica de datos.\n",
    "- Reconocer las **estructuras algebraicas fundamentales de problemas de decisión con restricciones**, tales como regiones factibles, variables de decisión, restricciones lineales y funciones objetivo, y relacionarlas con el comportamiento del algoritmo Simplex.\n",
    "- Identificar **problemas que requieren formulaciones no lineales, y conocer herramientas computacionales básicas para su solución**, reconociendo que estos métodos se basan en principios análogos a los de la programación lineal.\n",
    "- Diferenciar la **complejidad adicional que implica la optimización entera, y explorar alternativas aproximadas como heurísticas simples**, reconociendo sus ventajas y limitaciones en contextos prácticos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a3f7e35-c3ed-4e2b-98f7-ca6494850ecf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
