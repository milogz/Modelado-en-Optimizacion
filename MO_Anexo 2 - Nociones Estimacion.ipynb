{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7074b001-6156-4824-bf68-ed82bab5ff9a",
   "metadata": {},
   "source": [
    "# Anexo 2: Estimación y Regresión Lineal\n",
    "\n",
    "Este anexo complementa el notebook de **Estimación**, ofreciendo un panorama más formal e intuitivo de la regresión lineal, el método de **Mínimos Cuadrados Ordinarios (OLS)** y las principales métricas de evaluación. El propósito es servir de guía introductoria para estudiantes monitores y apoyar el tránsito hacia textos más completos como Greene, Montgomery & Runger, o Hastie et al.\n",
    "\n",
    "## 1. Panorama general\n",
    "\n",
    "La **estimación estadística** busca inferir relaciones entre variables a partir de datos observados. En particular, la **regresión lineal** intenta responder a preguntas como:\n",
    "\n",
    "- ¿Cómo se relaciona una variable respuesta \\(y\\) con factores explicativos \\(x\\)?\n",
    "- ¿Qué tanto de la variabilidad en \\(y\\) puede explicarse por un modelo lineal?\n",
    "- ¿Qué tan confiable es la predicción fuera de la muestra?\n",
    "\n",
    "En su forma más simple, una regresión lineal ajusta:\n",
    "\n",
    "$$\n",
    "y_i \\approx \\beta_0 + \\beta_1 x_{i1} + \\cdots + \\beta_p x_{ip} + \\epsilon_i\n",
    "$$\n",
    "\n",
    "donde \\(\\epsilon_i\\) es el error no explicado por el modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "797dfcc5-9b77-4ae7-8511-caaf334bcbbf",
   "metadata": {},
   "source": [
    "## 2. El método de Mínimos Cuadrados Ordinarios (OLS)\n",
    "\n",
    "La idea fundamental de OLS es elegir los parámetros \\(\\beta\\) que **minimizan la suma de cuadrados de los errores**:\n",
    "\n",
    "$$\n",
    "\\min_\\beta \\sum_{i=1}^n (y_i - \\hat{y}_i)^2\n",
    "$$\n",
    "\n",
    "Esta formulación se inspira en la geometría: se busca la “recta” (o hiperplano) que más cerca pase de todos los puntos en promedio.  \n",
    "\n",
    "- En **Geometría Lineal** (Montgomery & Runger), el ajuste equivale a proyectar el vector de respuestas \\(y\\) sobre el subespacio generado por las variables \\(X\\).  \n",
    "- En **Econometría** (Greene), se resalta que OLS es un **estimador insesgado** y consistente bajo supuestos clásicos.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5052513-dba8-4535-89af-f94cec79ca0c",
   "metadata": {},
   "source": [
    "## 3. Supuestos clásicos de OLS\n",
    "\n",
    "Aunque muchas veces se aplican sin verificarlos, es útil reconocerlos:\n",
    "\n",
    "1. **Linealidad en parámetros**: el modelo es lineal respecto a \\(\\beta\\).  \n",
    "2. **Exogeneidad**: \\(E[\\epsilon|X] = 0\\).  \n",
    "3. **Varianza constante de errores (homocedasticidad)**.  \n",
    "4. **No colinealidad perfecta** entre los regresores.  \n",
    "5. **Distribución normal de los errores** (útil para inferencia).  \n",
    "\n",
    "Estos supuestos permiten derivar propiedades óptimas del estimador y justificación de pruebas de hipótesis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e13c771a-6b89-4f1a-af59-4adc7538b9b2",
   "metadata": {},
   "source": [
    "## 4. Métricas de evaluación\n",
    "\n",
    "Un modelo no solo debe ajustarse, sino evaluarse:\n",
    "\n",
    "- **R² (Coeficiente de determinación):** mide proporción de variabilidad explicada.  \n",
    "- **Error Cuadrático Medio (MSE / RMSE):** magnitud típica del error en unidades de \\(y\\).  \n",
    "- **Error Absoluto Medio (MAE):** magnitud media sin penalizar cuadráticamente.  \n",
    "- **Validación cruzada:** divide los datos en entrenamiento/prueba, fundamental para evitar sobreajuste.  \n",
    "\n",
    "*(Ver Hastie, Tibshirani & Friedman, Cap. 3, para una visión moderna de validación y métricas).*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70e1b1e6-8de6-4758-bcab-d4e5e0365107",
   "metadata": {},
   "source": [
    "## 5. Más allá de OLS\n",
    "\n",
    "- En aplicaciones modernas, OLS es la base de técnicas más avanzadas (regresión ridge, lasso, modelos no lineales).  \n",
    "- El entendimiento profundo de sus supuestos y métricas es clave para interpretar correctamente cualquier resultado predictivo.\n",
    "\n",
    "### Referencias clave\n",
    "\n",
    "- Greene, W. H. (2012). *Econometric Analysis*. Pearson. (Cap. 2, fundamentos de OLS).  \n",
    "- Montgomery, D. C., & Runger, G. C. (2014). *Applied Statistics and Probability for Engineers*. Wiley. (Cap. 11, regresión simple y múltiple).  \n",
    "- Hastie, T., Tibshirani, R., & Friedman, J. (2009). *The Elements of Statistical Learning*. Springer. (Cap. 3, regresión y predicción).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "489a1a89-2c39-4dba-a14a-6aafe7a1b9bd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
